<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Mingdong Wu | 吴铭东</title> <meta name="author" content="Mingdong Wu"> <meta name="description" content="A third-year Ph.D. student in [Peking University (PKU)](https://english.pku.edu.cn/). "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/publication_preview/icon.jpg?7ab01e9c86da2e1140686eab5db74a7f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aaronanima.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Mingdong Wu | 吴铭东 </h1> <p class="desc">A third-year Ph.D. student in <a href="https://english.pku.edu.cn/" rel="external nofollow noopener" target="_blank">Peking University (PKU)</a>.</p> </header> <article> <div class="profile float-left"> <figure> <picture> <img src="/assets/img/wmd_23_10.jpg?fb5630a79ca031acb642da725858a671" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="wmd_23_10.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> </div> </div> <div class="clearfix"> <p>I am a final year Ph.D. student in the School of Computer Science at PKU, advised by Prof. <a href="https://cfcs.pku.edu.cn/english/people/faculty/haodong/index.htm" rel="external nofollow noopener" target="_blank">Hao Dong</a>. I received my bachelor degree in 2021, from <a href="https://cfcs.pku.edu.cn/english/research/turingprogram/introduction1/index.htm" rel="external nofollow noopener" target="_blank">Turing Class</a> in PKU. Currently, I am excited to be working with <a href="https://people.eecs.berkeley.edu/~jianlanluo/" rel="external nofollow noopener" target="_blank">Jianlan Luo</a> at <a href="https://www.agibot.com/" rel="external nofollow noopener" target="_blank">AgiBot</a> on some challenging problems. My recent research focuses on real world reinforcement learning algorithms and robotic systems with tactile sensing, building future data-flying-wheel applications.</p> <div class="social"> <div class="contact-icons"> <a href="mailto:%77%6D%69%6E%67%64@%70%6B%75.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0009-0007-9120-4621" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=MPfBNuIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/wmingd@pku.edu.cn" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> </div> <div class="contact-note"> </div> </div> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 10vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 8, 2024</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>RAL 2024</i> 🎉 </td> </tr> <tr> <th scope="row">Jul 1, 2024</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>ECCV 2024</i> 🎉 </td> </tr> <tr> <th scope="row">Sep 11, 2023</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>SIGGRAPH Asia 2023</i> 🎉 </td> </tr> <tr> <th scope="row">Sep 12, 2023</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>BMVC 2023 <b><font color="red">(Oral)</font></b></i> 🎉 </td> </tr> <tr> <th scope="row">Sep 22, 2023</th> <td> <b><font color="red">Three</font></b> paper gets accepted to <i>NeurIPS 2023</i> 🎉 </td> </tr> <tr> <th scope="row">Apr 18, 2023</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>RAL 2023</i> 🎉 </td> </tr> <tr> <th scope="row">Feb 28, 2023</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>CVPR 2023</i> 🎉 </td> </tr> <tr> <th scope="row">Sep 16, 2022</th> <td> <b><font color="red">One</font></b> paper gets accepted to <i>NeurIPS 2022</i> 🎉 </td> </tr> </table> </div> </div> <h2>Selected Publications</h2> <span>(*) indicates equal contribution </span> [<a href="/publications/" style="color: #48afd8; text-decoration: underline;">Full List</a>] <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS 2025</abbr></div> <div id="wu2025simlauncher" class="col-sm-7"> <div class="title">SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training</div> <div class="author"> <em>Mingdong Wu*</em>, Lehong Wu*, Yizhuo Wu*, Weiyao Huang, Hongwei Fan, Zheyuan Hu, Haoran Geng, Jinzhou Li, Jiahe Ying, Long Yang, and  others</div> <div class="periodical"> <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2507.04452" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.dropbox.com/scl/fi/5yif7dl2bz4pcv2uw9s03/Training-Timelapse.mp4?rlkey=iga15684bqfy2fz9fwk6edsay&amp;st=mryoerqt&amp;dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2025simlauncher</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.dropbox.com/scl/fi/5yif7dl2bz4pcv2uw9s03/Training-Timelapse.mp4?rlkey=iga15684bqfy2fz9fwk6edsay&amp;st=mryoerqt&amp;dl=0}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Mingdong and Wu*, Lehong and Wu*, Yizhuo and Huang, Weiyao and Fan, Hongwei and Hu, Zheyuan and Geng, Haoran and Li, Jinzhou and Ying, Jiahe and Yang, Long and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/simlauncher.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CoRL 2025</abbr></div> <div id="wu2025unitac2pose" class="col-sm-7"> <div class="title">UniTac2Pose: A Unified Approach Learned in Simulation for Generalizable Visuotactile In-hand Pose Estimation</div> <div class="author"> <em>Mingdong Wu*</em>, Long Yan*, Jin Liu*, Weiyao Huang, Lehong Wu, Zelin Chen, Daolin Ma, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Coming%20Soon" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2025unitac2pose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UniTac2Pose: A Unified Approach Learned in Simulation for Generalizable Visuotactile In-hand Pose Estimation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Mingdong and Yan*, Long and Liu*, Jin and Huang, Weiyao and Wu, Lehong and Chen, Zelin and Ma, Daolin and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Conference on Robot Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/unitac2pose.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS 2025</abbr></div> <div id="li2025adaptive" class="col-sm-7"> <div class="title">Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation</div> <div class="author"> Jinzhou Li*, <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu*</a>, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, Zeyuan Chen, Haotian Jin, <em>Mingdong Wu</em>, Yujun Shen, Yaodong Yang, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2505.13982" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2025adaptive</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li*, Jinzhou and Wu*, Tianhao and Zhang, Jiyao and Chen, Zeyuan and Jin, Haotian and Wu, Mingdong and Shen, Yujun and Yang, Yaodong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/adaptac-dex.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICRA 2025</abbr></div> <div id="wu2024canonical" class="col-sm-7"> <div class="title">Canonical representation and force-based pretraining of 3d tactile for dexterous visuo-tactile policy learning</div> <div class="author"> <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu</a>, Jinzhou Li*, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang*</a>, <em>Mingdong Wu</em>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.07579.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2024canonical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Canonical representation and force-based pretraining of 3d tactile for dexterous visuo-tactile policy learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Tianhao and Li*, Jinzhou and Zhang*, Jiyao and Wu, Mingdong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/canonical.gif"></div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV 2024</abbr></div> <div id="zhang2024omni6dpose" class="col-sm-7"> <div class="title">Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking</div> <div class="author"> <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang*</a>, Weiyao Huang*, Bo Peng*, <em>Mingdong Wu</em>, Fei Hu, Zijian Chen, Bo Zhao, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>European Conference on Computer Vision</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.04316" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://jiyao06.github.io/Omni6DPose/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024omni6dpose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Jiyao and Huang*, Weiyao and Peng*, Bo and Wu, Mingdong and Hu, Fei and Chen, Zijian and Zhao, Bo and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/omni6dpose.jpg"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RAL 2024</abbr></div> <div id="zeng2023distilling" class="col-sm-7"> <div class="title">Distilling Functional Rearrangement Priors from Large Models</div> <div class="author"> Yiming Zeng*, <em>Mingdong Wu*</em>, Long Yang, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, Hao Ding, Hui Cheng, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2312.01474.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/lvdiffusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zeng2023distilling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distilling Functional Rearrangement Priors from Large Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zeng*, Yiming and Wu*, Mingdong and Yang, Long and Zhang, Jiyao and Ding, Hao and Cheng, Hui and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/lvdiffusion_v2.gif"></div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2023</abbr></div> <div id="zhang2023genpose" class="col-sm-7"> <div class="title">GenPose: Generative Category-level Object Pose Estimation via Diffusion Models</div> <div class="author"> <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang*</a>, <em>Mingdong Wu*</em>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2306.10531v1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/genpose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/Jiyao06/GenPose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;label=Code+Stars" alt="code"> <a href="https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275" alt="PWC"></a> <a href="https://mp.weixin.qq.com/s/RYV_aap9eYtwX_4_Ghr5Vw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> 机器之心 </a> </div> <div class="abstract hidden"> <p> We explore a pure generative approach to tackle the multi-hypothesis issue in 6D Category-level Object Pose Estimation. The key idea is to generate pose candidates using a score-based diffusion model and filter out outliers using an energy-based diffusion model. By aggregating the remaining candidates, we can obtain a robust and high-quality output pose. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2023genpose</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{机器之心}</span><span class="p">,</span>
  <span class="na">news_link</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/RYV_aap9eYtwX_4_Ghr5Vw}</span><span class="p">,</span>
  <span class="na">sota_link</span> <span class="p">=</span> <span class="s">{https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose}</span><span class="p">,</span>
  <span class="na">sota_badge</span> <span class="p">=</span> <span class="s">{https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GenPose: Generative Category-level Object Pose Estimation via Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Jiyao and Wu*, Mingdong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/GenPose_V2.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2023</abbr></div> <div id="wu2023learning" class="col-sm-7"> <div class="title">Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping</div> <div class="author"> <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu*</a>, <em>Mingdong Wu*</em>, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, <a href="https://cn.linkedin.com/in/yunchong-gan" rel="external nofollow noopener" target="_blank">Yunchong Gan</a>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.06038" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/graspgf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/tianhaowuhz/human-assisting-dex-grasp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/tianhaowuhz/human-assisting-dex-grasp?style=social&amp;label=Code+Stars" alt="code"> <a href="https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> 新智元 </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2023learning</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{新智元}</span><span class="p">,</span>
  <span class="na">news_link</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/tianhaowuhz/human-assisting-dex-grasp?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Tianhao and Wu*, Mingdong and Zhang, Jiyao and Gan, Yunchong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/graspgf_v3.gif"></div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2022</abbr></div> <div id="wu2022targf" class="col-sm-7"> <div class="title">TarGF: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification</div> <div class="author"> <em>Mingdong Wu*</em>, <a href="https://fangweizhong.xyz/" rel="external nofollow noopener" target="_blank">Fangwei Zhong*</a>, Yulong Xia, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2209.00853" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/targf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a><a href="https://github.com/AaronAnima/TarGF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p> We study object rearrangement without explicit goal specification. The agent is given examples from a target distribution and aims at rearranging objects to increase the likelihood of the distribution. Our key idea is to learn a target gradient field that indicates the fastest direction to increase the likelihood from examples via score-matching. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wu2022targf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tar{GF}: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Mingdong and Zhong*, Fangwei and Xia, Yulong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, Alice H. and Agarwal, Alekh and Belgrave, Danielle and Cho, Kyunghyun}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=Euv1nXN98P3}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/targf_update.gif"></div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Mingdong Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. The template is stolen from <a href="https://haici.cc/" rel="external nofollow noopener" target="_blank">Hai Ci</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>