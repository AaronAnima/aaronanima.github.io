<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Mingdong Wu | 吴铭东</title> <meta name="author" content="Mingdong Wu"> <meta name="description" content="(*) indicates equal contribution"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/publication_preview/icon.jpg?7ab01e9c86da2e1140686eab5db74a7f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aaronanima.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Mingdong Wu | 吴铭东</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">(*) indicates equal contribution</p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CoRL 2025</abbr></div> <div id="wu2025unitac2pose" class="col-sm-7"> <div class="title">UniTac2Pose: A Unified Approach Learned in Simulation for Generalizable Visuotactile In-hand Pose Estimation</div> <div class="author"> <em>Mingdong Wu</em>, Long Yang, Jin Liu, Weiyao Huang, Lehong Wu, Zelin Chen, Daolin Ma, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>CoRL 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Coming%20Soon" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2025unitac2pose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UniTac2Pose: A Unified Approach Learned in Simulation for Generalizable Visuotactile In-hand Pose Estimation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Mingdong and Yang, Long and Liu, Jin and Huang, Weiyao and Wu, Lehong and Chen, Zelin and Ma, Daolin and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRL 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/unitac2pose.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS 2025</abbr></div> <div id="wu2025simlauncher" class="col-sm-7"> <div class="title">SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training</div> <div class="author"> <em>Mingdong Wu</em>, Lehong Wu, Yizhuo Wu, Weiyao Huang, Hongwei Fan, Zheyuan Hu, Haoran Geng, Jinzhou Li, Jiahe Ying, Long Yang, and  others</div> <div class="periodical"> <em>IROS 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2507.04452" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.dropbox.com/scl/fi/5yif7dl2bz4pcv2uw9s03/Training-Timelapse.mp4?rlkey=iga15684bqfy2fz9fwk6edsay&amp;st=mryoerqt&amp;dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2025simlauncher</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.dropbox.com/scl/fi/5yif7dl2bz4pcv2uw9s03/Training-Timelapse.mp4?rlkey=iga15684bqfy2fz9fwk6edsay&amp;st=mryoerqt&amp;dl=0}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Mingdong and Wu, Lehong and Wu, Yizhuo and Huang, Weiyao and Fan, Hongwei and Hu, Zheyuan and Geng, Haoran and Li, Jinzhou and Ying, Jiahe and Yang, Long and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IROS 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/simlauncher.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS 2025</abbr></div> <div id="li2025adaptive" class="col-sm-7"> <div class="title">Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation</div> <div class="author"> Jinzhou Li, <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu</a>, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, Zeyuan Chen, Haotian Jin, <em>Mingdong Wu</em>, Yujun Shen, Yaodong Yang, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IROS 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2505.13982" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2025adaptive</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Jinzhou and Wu, Tianhao and Zhang, Jiyao and Chen, Zeyuan and Jin, Haotian and Wu, Mingdong and Shen, Yujun and Yang, Yaodong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IROS 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/adaptac-dex.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR 2025</abbr></div> <div id="wang2025adamanip" class="col-sm-7"> <div class="title">Adamanip: Adaptive articulated object manipulation environments and policy learning</div> <div class="author"> Yuanfei Wang, Xiaojie Zhang, Ruihai Wu, Yu Li, Yan Shen, <em>Mingdong Wu</em>, Zhaofeng He, <a href="https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang" rel="external nofollow noopener" target="_blank">Yizhou Wang</a>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>ICLR 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2502.11124" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2025adamanip</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adamanip: Adaptive articulated object manipulation environments and policy learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Yuanfei and Zhang, Xiaojie and Wu, Ruihai and Li, Yu and Shen, Yan and Wu, Mingdong and He, Zhaofeng and Wang, Yizhou and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ICLR 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/AdaManip.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RSS 2025</abbr></div> <div id="fu2025cordvip" class="col-sm-7"> <div class="title">Cordvip: Correspondence-based visuomotor policy for dexterous manipulation in real-world</div> <div class="author"> Yankai Fu, Qiuxuan Feng, Ning Chen, Zichen Zhou, Mengzhen Liu, <em>Mingdong Wu</em>, Tianxing Chen, Shanyu Rong, Jiaming Liu, <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a>, and  others</div> <div class="periodical"> <em>RSS 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2502.08449.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fu2025cordvip</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cordvip: Correspondence-based visuomotor policy for dexterous manipulation in real-world}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fu, Yankai and Feng, Qiuxuan and Chen, Ning and Zhou, Zichen and Liu, Mengzhen and Wu, Mingdong and Chen, Tianxing and Rong, Shanyu and Liu, Jiaming and Dong, Hao and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{RSS 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/Cordvip.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICCV 2025</abbr></div> <div id="xue2024gfpack++" class="col-sm-7"> <div class="title">GFPack++: Improving 2D Irregular Packing by Learning Gradient Field with Attention</div> <div class="author"> <a href="https://timhsue.github.io/" rel="external nofollow noopener" target="_blank">Tianyang Xue</a>, Lin Lv, Yang Liu, Wu Mingdong, Dong Hao, Zhang Yanbin, Han Renmin, and Chen Baoquan</div> <div class="periodical"> <em>ICCV 2025</em>, 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.07579.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xue2024gfpack++</span><span class="p">,</span>
  <span class="na">oral</span> <span class="p">=</span> <span class="s">{Highlight}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GFPack++: Improving 2D Irregular Packing by Learning Gradient Field with Attention}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xue, Tianyang and Lv, Lin and Liu, Yang and Mingdong, Wu and Hao, Dong and Yanbin, Zhang and Renmin, Han and Baoquan, Chen}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ICCV 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"></div> </div> </li> </ol> <h2 class="year">2024</h2> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICRA 2025</abbr></div> <div id="wu2024canonical" class="col-sm-7"> <div class="title">Canonical representation and force-based pretraining of 3d tactile for dexterous visuo-tactile policy learning</div> <div class="author"> <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu</a>, Jinzhou Li, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, <em>Mingdong Wu</em>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>ICRA 2025</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.07579.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2024canonical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Canonical representation and force-based pretraining of 3d tactile for dexterous visuo-tactile policy learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Tianhao and Li, Jinzhou and Zhang, Jiyao and Wu, Mingdong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ICRA 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/canonical.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2024</abbr></div> <div id="wang2024mo" class="col-sm-7"> <div class="title">MO-DDN: A Coarse-to-Fine Attribute-based Exploration Agent for Multi-object Demand-driven Navigation</div> <div class="author"> <a href="https://whcpumpkin.github.io/" rel="external nofollow noopener" target="_blank">Hongcheng Wang</a>, Peiqi Liu, Wenzhe Cai, <em>Mingdong Wu</em>, Zhengyu Qian, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>NeurIPS 2024</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/7565f036ceb20a2c74d341bfaa9fffad-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2024mo</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MO-DDN: A Coarse-to-Fine Attribute-based Exploration Agent for Multi-object Demand-driven Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Hongcheng and Liu, Peiqi and Cai, Wenzhe and Wu, Mingdong and Qian, Zhengyu and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeurIPS 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/NIPS-2024-MODDN.svg"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Arxiv 2024</abbr></div> <div id="zhang2024unidexfpm" class="col-sm-7"> <div class="title">UniDexFPM: Universal Dexterous Functional Pre-grasp Manipulation Via Diffusion Policy</div> <div class="author"> <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu*</a>, <a href="https://cn.linkedin.com/in/yunchong-gan" rel="external nofollow noopener" target="_blank">Yunchong Gan*</a>, <em>Mingdong Wu</em>, Jingbo Cheng, Yaodong Yang, Yixin Zhu, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Under Review</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2403.12421.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://unidexfpm.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024unidexfpm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UniDexFPM: Universal Dexterous Functional Pre-grasp Manipulation Via Diffusion Policy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Tianhao and Gan*, Yunchong and Wu, Mingdong and Cheng, Jingbo and Yang, Yaodong and Zhu, Yixin and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Under Review}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/unidexfpm.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV 2024</abbr></div> <div id="zhang2024omni6dpose" class="col-sm-7"> <div class="title">Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking</div> <div class="author"> <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang*</a>, Weiyao Huang*, Bo Peng*, <em>Mingdong Wu</em>, Fei Hu, Zijian Chen, Bo Zhao, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>European Conference on Computer Vision</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.04316" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://jiyao06.github.io/Omni6DPose/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024omni6dpose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Jiyao and Huang*, Weiyao and Peng*, Bo and Wu, Mingdong and Hu, Fei and Chen, Zijian and Zhao, Bo and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/omni6dpose.jpg"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RAL 2024</abbr></div> <div id="zeng2023distilling" class="col-sm-7"> <div class="title">Distilling Functional Rearrangement Priors from Large Models</div> <div class="author"> Yiming Zeng*, <em>Mingdong Wu*</em>, Long Yang, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, Hao Ding, Hui Cheng, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2312.01474.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/lvdiffusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zeng2023distilling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distilling Functional Rearrangement Priors from Large Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zeng*, Yiming and Wu*, Mingdong and Yang, Long and Zhang, Jiyao and Ding, Hao and Cheng, Hui and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/lvdiffusion_v2.gif"></div> </div> </li> </ol> <h2 class="year">2023</h2> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2023</abbr></div> <div id="zhang2023genpose" class="col-sm-7"> <div class="title">GenPose: Generative Category-level Object Pose Estimation via Diffusion Models</div> <div class="author"> <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang*</a>, <em>Mingdong Wu*</em>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2306.10531v1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/genpose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/Jiyao06/GenPose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;label=Code+Stars" alt="code"> <a href="https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275" alt="PWC"></a> <a href="https://mp.weixin.qq.com/s/RYV_aap9eYtwX_4_Ghr5Vw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> 机器之心 </a> </div> <div class="abstract hidden"> <p> We explore a pure generative approach to tackle the multi-hypothesis issue in 6D Category-level Object Pose Estimation. The key idea is to generate pose candidates using a score-based diffusion model and filter out outliers using an energy-based diffusion model. By aggregating the remaining candidates, we can obtain a robust and high-quality output pose. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2023genpose</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{机器之心}</span><span class="p">,</span>
  <span class="na">news_link</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/RYV_aap9eYtwX_4_Ghr5Vw}</span><span class="p">,</span>
  <span class="na">sota_link</span> <span class="p">=</span> <span class="s">{https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose}</span><span class="p">,</span>
  <span class="na">sota_badge</span> <span class="p">=</span> <span class="s">{https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GenPose: Generative Category-level Object Pose Estimation via Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Jiyao and Wu*, Mingdong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/GenPose_V2.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2023</abbr></div> <div id="wu2023learning" class="col-sm-7"> <div class="title">Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping</div> <div class="author"> <a href="https://tianhaowuhz.github.io/" rel="external nofollow noopener" target="_blank">Tianhao Wu*</a>, <em>Mingdong Wu*</em>, <a href="https://jiyao06.github.io/" rel="external nofollow noopener" target="_blank">Jiyao Zhang</a>, <a href="https://cn.linkedin.com/in/yunchong-gan" rel="external nofollow noopener" target="_blank">Yunchong Gan</a>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.06038" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/graspgf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/tianhaowuhz/human-assisting-dex-grasp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/tianhaowuhz/human-assisting-dex-grasp?style=social&amp;label=Code+Stars" alt="code"> <a href="https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> 新智元 </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2023learning</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{新智元}</span><span class="p">,</span>
  <span class="na">news_link</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/tianhaowuhz/human-assisting-dex-grasp?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Tianhao and Wu*, Mingdong and Zhang, Jiyao and Gan, Yunchong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/graspgf_v3.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2023</abbr></div> <div id="wang2023find" class="col-sm-7"> <div class="title">Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation</div> <div class="author"> <a href="https://whcpumpkin.github.io/" rel="external nofollow noopener" target="_blank">Hongcheng Wang</a>, Andy Guan Hong Chen, <a href="https://clorislili.github.io/clorisLi/" rel="external nofollow noopener" target="_blank">Xiaoqi Li</a>, <em>Mingdong Wu</em>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.08138" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/demand-driven-navigation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/whcpumpkin/Demand-driven-navigation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/whcpumpkin/Demand-driven-navigation?style=social&amp;label=Code+Stars" alt="code"> <a href="https://mp.weixin.qq.com/s/Sj2q02VkY6HMzHDot6X9_w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> 机器之心 </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2023find</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{机器之心}</span><span class="p">,</span>
  <span class="na">news_link</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/Sj2q02VkY6HMzHDot6X9_w}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/whcpumpkin/Demand-driven-navigation?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Hongcheng and Chen, Andy Guan Hong and Li, Xiaoqi and Wu, Mingdong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/demand_nav_v3.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SIGGRAPH Asia<br>2023</abbr></div> <div id="Xue2023learning" class="col-sm-7"> <div class="title">Learning Gradient Fields for Scalable and Generalizable Irregular Packing</div> <div class="author"> <a href="https://timhsue.github.io/" rel="external nofollow noopener" target="_blank">Tianyang Xue*</a>, <em>Mingdong Wu*</em>, <a href="http://irc.cs.sdu.edu.cn/~lulin/index.html" rel="external nofollow noopener" target="_blank">Lin Lu</a>, Haoxuan Wang, <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a>, and <a href="http://baoquanchen.info/" rel="external nofollow noopener" target="_blank">Baoquan Chen</a> </div> <div class="periodical"> <em>SIGGRAPH Asia</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2310.19814" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/gfpack" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Xue2023learning</span><span class="p">,</span>
  <span class="na">abbryear</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Gradient Fields for Scalable and Generalizable Irregular Packing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xue*, Tianyang and Wu*, Mingdong and Lu, Lin and Wang, Haoxuan and Dong, Hao and Chen, Baoquan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{SIGGRAPH Asia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/gf_packing_v3.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">BMVC 2023</abbr><br><span class="award badge">Oral</span> </div> <div id="cheng2023score" class="col-sm-7"> <div class="title">Score-PA: Score-based 3D Part Assembly</div> <div class="author"> Junfeng Cheng, <em>Mingdong Wu</em>, <a href="https://github.com/Ruiyuan-Zhang" rel="external nofollow noopener" target="_blank">Ruiyuan Zhang</a>, <a href="https://championchess.github.io/" rel="external nofollow noopener" target="_blank">Guanqi Zhan</a>, <a href="https://wuchaozju.github.io/" rel="external nofollow noopener" target="_blank">Chao Wu</a>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>British Machine Vision Conference</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2309.04220v1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a><a href="https://github.com/J-F-Cheng/Score-PA_Score-based-3D-Part-Assembly" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cheng2023score</span><span class="p">,</span>
  <span class="na">oral</span> <span class="p">=</span> <span class="s">{Oral}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Score-PA: Score-based 3D Part Assembly}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cheng, Junfeng and Wu, Mingdong and Zhang, Ruiyuan and Zhan, Guanqi and Wu, Chao and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{British Machine Vision Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/score_pa_v2.gif"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RAL 2023</abbr></div> <div id="wang2023learning" class="col-sm-7"> <div class="title">Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation</div> <div class="author"> <a href="https://whcpumpkin.github.io/" rel="external nofollow noopener" target="_blank">Hongcheng Wang</a>, Yuxuan Wang, <a href="https://fangweizhong.xyz/" rel="external nofollow noopener" target="_blank">Fangwei Zhong</a>, <em>Mingdong Wu</em>, Jianwei Zhang, <a href="https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang" rel="external nofollow noopener" target="_blank">Yizhou Wang</a>, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2304.10773.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/sasavan/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a><a href="https://github.com/wwwwwyyyyyxxxxx/SA2GVAN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2023learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Hongcheng and Wang, Yuxuan and Zhong, Fangwei and Wu, Mingdong and Zhang, Jianwei and Wang, Yizhou and Dong, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/2023RAL-Visual-Audio-Nav-min.png"></div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CVPR 2023</abbr></div> <div id="ci2023gfpose" class="col-sm-7"> <div class="title">GFPose: Learning 3d human pose prior with gradient fields</div> <div class="author"> <a href="https://haici.cc/" rel="external nofollow noopener" target="_blank">Hai Ci</a>, <em>Mingdong Wu</em>, <a href="https://weotao.live/" rel="external nofollow noopener" target="_blank">Wentao Zhu</a>, <a href="https://shirleymaxx.github.io" rel="external nofollow noopener" target="_blank">Xiaoxuan Ma</a>, <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a>, <a href="https://fangweizhong.xyz/" rel="external nofollow noopener" target="_blank">Fangwei Zhong</a>, and <a href="https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang" rel="external nofollow noopener" target="_blank">Yizhou Wang</a> </div> <div class="periodical"> <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2212.08641" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/gfpose/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://github.com/Embracing/GFPose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a><img src="https://img.shields.io/github/stars/Embracing/GFPose?style=social&amp;label=Code+Stars" alt="code"> <a href="https://paperswithcode.com/sota/multi-hypotheses-3d-human-pose-estimation-on?p=gfpose-learning-3d-human-pose-prior-with" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/gfpose-learning-3d-human-pose-prior-with/multi-hypotheses-3d-human-pose-estimation-on" alt="PWC"></a> </div> <div class="abstract hidden"> <p> GFPose is a unified 3D human pose prior model that can be easily used for various applications, e.g., 3D human pose estimation, pose denoising and generation. Our key idea is to estimate the gradient field (a.k.a, score) of the perturbed human pose. We can leverage the gradient to adjust poses to be more plausible and feasible to a task specification. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ci2023gfpose</span><span class="p">,</span>
  <span class="na">sota_link</span> <span class="p">=</span> <span class="s">{https://paperswithcode.com/sota/multi-hypotheses-3d-human-pose-estimation-on?p=gfpose-learning-3d-human-pose-prior-with}</span><span class="p">,</span>
  <span class="na">sota_badge</span> <span class="p">=</span> <span class="s">{https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/gfpose-learning-3d-human-pose-prior-with/multi-hypotheses-3d-human-pose-estimation-on}</span><span class="p">,</span>
  <span class="na">star</span> <span class="p">=</span> <span class="s">{https://img.shields.io/github/stars/Embracing/GFPose?style=social&amp;amp;label=Code+Stars}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GFPose: Learning 3d human pose prior with gradient fields}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ci, Hai and Wu, Mingdong and Zhu, Wentao and Ma, Xiaoxuan and Dong, Hao and Zhong, Fangwei and Wang, Yizhou}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4800--4810}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/gfpose_v2.gif"></div> </div> </li> </ol> <h2 class="year">2022</h2> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS 2022</abbr></div> <div id="wu2022targf" class="col-sm-7"> <div class="title">TarGF: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification</div> <div class="author"> <em>Mingdong Wu*</em>, <a href="https://fangweizhong.xyz/" rel="external nofollow noopener" target="_blank">Fangwei Zhong*</a>, Yulong Xia, and <a href="https://zsdonghao.github.io/" rel="external nofollow noopener" target="_blank">Hao Dong</a> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2209.00853" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/targf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a><a href="https://github.com/AaronAnima/TarGF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p> We study object rearrangement without explicit goal specification. The agent is given examples from a target distribution and aims at rearranging objects to increase the likelihood of the distribution. Our key idea is to learn a target gradient field that indicates the fastest direction to increase the likelihood from examples via score-matching. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wu2022targf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tar{GF}: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Mingdong and Zhong*, Fangwei and Xia, Yulong and Dong, Hao}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, Alice H. and Agarwal, Alekh and Belgrave, Danielle and Cho, Kyunghyun}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=Euv1nXN98P3}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-3 preview"><img class="preview z-depth-2 rounded" src="/assets/img/publication_preview/targf_update.gif"></div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Mingdong Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. The template is stolen from <a href="https://haici.cc/" rel="external nofollow noopener" target="_blank">Hai Ci</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>