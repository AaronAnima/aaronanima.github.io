---
---

@article{zhang2023genpose,
  sota_link={https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose},
  sota_badge={https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275},
  code={https://github.com/Jiyao06/GenPose},
  star={https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;label=Code+Stars},
  preview={GenPose_V2.gif},
  pdf={https://arxiv.org/pdf/2306.10531v1.pdf},
  abbr={NeurIPS},
  bibtex_show={true},
  selected={true},
  title={GenPose: Generative Category-level Object Pose Estimation via Diffusion Models},
  author={Zhang*, Jiyao and Wu*, Mingdong and Dong, Hao},
  journal={Advances in Neural Information Processing Systems},
  year={2023},
  abstract={
    We explore a pure generative approach to tackle the multi-hypothesis issue in 6D Category-level Object Pose Estimation. 
    The key idea is to generate pose candidates using a score-based diffusion model and filter out outliers using an energy-based diffusion model. 
    By aggregating the remaining candidates, we can obtain a robust and high-quality output pose.
  }
}

@article{wu2023learning,
  preview={graspgf_v3.gif},
  pdf={https://arxiv.org/abs/2309.06038},
  website={https://sites.google.com/view/graspgf},
  abbr={NeurIPS},
  bibtex_show={true},
  selected={true},
  title={Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping},
  author={Wu*, Tianhao and Wu*, Mingdong and Zhang, Jiyao and Gan, Yunchong and Dong, Hao},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}


@article{wang2023find,
  preview={demand_nav_v2.gif},
  pdf={https://arxiv.org/abs/2309.08138},
  abbr={NeurIPS},
  bibtex_show={true},
  selected={true},
  title={Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation},
  author={Wang, Hongcheng and Chen, Andy Guan Hong and Li, Xiaoqi and Wu, Mingdong and Dong, Hao},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}


@article{Xue2023learning,
  preview={gf_packing_v3.gif},
  pdf={https://arxiv.org/abs/2310.19814},
  website={https://sites.google.com/view/gfpack},
  abbr={SIGGRAPH Asia},
  bibtex_show={true},
  selected={true},
  title={Learning Gradient Fields for Scalable and Generalizable Irregular Packing},
  author={Xue*, Tianyang and Wu*, Mingdong and Lu, Lin and Wang, Haoxuan and Dong, Hao and Chen, Baoquan},
  journal={SIGGRAPH Asia},
  year={2023}
}


@article{cheng2023score,
  code={https://github.com/J-F-Cheng/Score-PA_Score-based-3D-Part-Assembly},
  preview={score_pa_v2.gif},
  pdf={https://arxiv.org/pdf/2309.04220v1.pdf},
  oral="Oral",
  abbr={BMVC},
  bibtex_show={true},
  selected={true},
  title={Score-PA: Score-based 3D Part Assembly},
  author={Cheng, Junfeng and Wu, Mingdong and Zhang, Ruiyuan and Zhan, Guanqi and Wu, Chao and Dong, Hao},
  journal={British Machine Vision Conference},
  year={2023}
}


@article{wang2023learning,
  website={https://sites.google.com/view/sasavan/},
  code={https://github.com/wwwwwyyyyyxxxxx/SA2GVAN},
  preview={2023RAL-Visual-Audio-Nav-min.png},
  pdf={https://arxiv.org/pdf/2304.10773.pdf},
  abbr={RAL},
  bibtex_show={true},
  selected={true},
  title={Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation},
  author={Wang, Hongcheng and Wang, Yuxuan and Zhong, Fangwei and Wu, Mingdong and Zhang, Jianwei and Wang, Yizhou and Dong, Hao},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}


@inproceedings{ci2023gfpose,
  sota_link={https://paperswithcode.com/sota/multi-hypotheses-3d-human-pose-estimation-on?p=gfpose-learning-3d-human-pose-prior-with},
  sota_badge={https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/gfpose-learning-3d-human-pose-prior-with/multi-hypotheses-3d-human-pose-estimation-on},
  website={https://sites.google.com/view/gfpose/home},
  code={https://github.com/Embracing/GFPose},
  star={https://img.shields.io/github/stars/Embracing/GFPose?style=social&amp;label=Code+Stars},
  preview={gfpose_v2.gif},
  pdf={https://arxiv.org/abs/2212.08641},
  abbr={CVPR},
  bibtex_show={true},
  selected={true},
  title={GFPose: Learning 3d human pose prior with gradient fields},
  author={Ci, Hai and Wu, Mingdong and Zhu, Wentao and Ma, Xiaoxuan and Dong, Hao and Zhong, Fangwei and Wang, Yizhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4800--4810},
  year={2023},
  abstract={
    GFPose is a unified 3D human pose prior model that can be easily used for various applications, e.g., 3D human pose estimation, pose denoising and generation. 
    Our key idea is to estimate the gradient field (a.k.a, score) of the perturbed human pose. 
    We can leverage the gradient to adjust poses to be more plausible and feasible to a task specification. 
  }
}


@inproceedings{wu2022targf,
  website={https://sites.google.com/view/targf},
  code={https://github.com/AaronAnima/TarGF},
  preview={targf_update.gif},
  pdf={https://arxiv.org/abs/2209.00853},
  abbr={NeurIPS},
  bibtex_show={true},
  selected={true},
  title={Tar{GF}: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification},
  author={Wu*, Mingdong and Zhong*, Fangwei and Xia, Yulong and Dong, Hao},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=Euv1nXN98P3},
  abstract={
    We study object rearrangement without explicit goal specification.
    The agent is given examples from a target distribution and aims at rearranging objects to increase the likelihood of the distribution.
    Our key idea is to learn a target gradient field that indicates the fastest direction to increase the likelihood from examples via score-matching.
  }
}



