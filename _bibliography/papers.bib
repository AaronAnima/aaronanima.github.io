---
---




@article{zhang2024unidexfpm,
  website={https://unidexfpm.github.io/},
  preview={unidexfpm.png},
  pdf={https://arxiv.org/pdf/2403.12421.pdf},
  abbr={Arxiv 2024},
  bibtex_show={false},
  selected={true},
  title={UniDexFPM: Universal Dexterous Functional Pre-grasp Manipulation Via Diffusion Policy},
  author={Wu*, Tianhao and Gan*, Yunchong and Wu, Mingdong and Cheng, Jingbo and Yang, Yaodong and Zhu, Yixin and Dong, Hao},
  journal={Under Review},
  year={2024},
}


@article{zhang2024omni6dpose,
  website={https://jiyao06.github.io/Omni6DPose/},
  preview={omni6dpose.jpg},
  pdf={https://arxiv.org/pdf/2406.04316},
  abbr={ECCV 2024},
  bibtex_show={false},
  selected={true},
  title={Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking},
  author={Zhang*, Jiyao and Huang*, Weiyao and Peng*, Bo and Wu, Mingdong and Hu, Fei and Chen, Zijian and Zhao, Bo and Dong, Hao},
  journal={European Conference on Computer Vision},
  year={2024},
}


@article{zeng2023distilling,
  website={https://sites.google.com/view/lvdiffusion},
  preview={lvdiffusion_v2.gif},
  pdf={https://arxiv.org/pdf/2312.01474.pdf},
  abbr={RAL 2024},
  bibtex_show={false},
  selected={true},
  title={Distilling Functional Rearrangement Priors from Large Models},
  author={Wu*, Mingdong and Zeng*, Yiming and Yang, Long and Zhang, Jiyao and Ding, Hao and Cheng, Hui and Dong, Hao},
  journal={IEEE Robotics and Automation Letters},
  year={2024},
}

@article{zhang2023genpose,
  news={机器之心},
  news_link={https://mp.weixin.qq.com/s/RYV_aap9eYtwX_4_Ghr5Vw},
  sota_link={https://paperswithcode.com/sota/6d-pose-estimation-using-rgbd-on-real275?p=genpose-generative-category-level-object-pose},
  sota_badge={https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/genpose-generative-category-level-object-pose/6d-pose-estimation-using-rgbd-on-real275},
  code={https://github.com/Jiyao06/GenPose},
  website={https://sites.google.com/view/genpose},
  star={https://img.shields.io/github/stars/Jiyao06/GenPose?style=social&amp;label=Code+Stars},
  preview={GenPose_V2.gif},
  pdf={https://arxiv.org/pdf/2306.10531v1.pdf},
  abbr={NeurIPS 2023},
  bibtex_show={true},
  selected={true},
  title={GenPose: Generative Category-level Object Pose Estimation via Diffusion Models},
  author={Zhang*, Jiyao and Wu*, Mingdong and Dong, Hao},
  journal={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023},
  abstract={
    We explore a pure generative approach to tackle the multi-hypothesis issue in 6D Category-level Object Pose Estimation. 
    The key idea is to generate pose candidates using a score-based diffusion model and filter out outliers using an energy-based diffusion model. 
    By aggregating the remaining candidates, we can obtain a robust and high-quality output pose.
  }
}

@article{wu2023learning,
  news={新智元},
  news_link={https://mp.weixin.qq.com/s/hpzZWMizR8tPSGIvGVjPoA},
  preview={graspgf_v3.gif},
  pdf={https://arxiv.org/abs/2309.06038},
  website={https://sites.google.com/view/graspgf},
  code={https://github.com/tianhaowuhz/human-assisting-dex-grasp},
  star={https://img.shields.io/github/stars/tianhaowuhz/human-assisting-dex-grasp?style=social&amp;label=Code+Stars},
  abbr={NeurIPS 2023},
  bibtex_show={true},
  selected={true},
  title={Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping},
  author={Wu*, Tianhao and Wu*, Mingdong and Zhang, Jiyao and Gan, Yunchong and Dong, Hao},
  journal={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023},
}


@article{wang2023find,
  news={机器之心},
  news_link={https://mp.weixin.qq.com/s/Sj2q02VkY6HMzHDot6X9_w},
  preview={demand_nav_v3.gif},
  pdf={https://arxiv.org/abs/2309.08138},
  website={https://sites.google.com/view/demand-driven-navigation},
  code={https://github.com/whcpumpkin/Demand-driven-navigation},
  star={https://img.shields.io/github/stars/whcpumpkin/Demand-driven-navigation?style=social&amp;label=Code+Stars},
  abbr={NeurIPS 2023},
  bibtex_show={true},
  selected={false},
  title={Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation},
  author={Wang, Hongcheng and Chen, Andy Guan Hong and Li, Xiaoqi and Wu, Mingdong and Dong, Hao},
  journal={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}


@article{Xue2023learning,
  preview={gf_packing_v3.gif},
  pdf={https://arxiv.org/abs/2310.19814},
  website={https://sites.google.com/view/gfpack},
  abbr={SIGGRAPH Asia},
  abbryear={2023}
  bibtex_show={true},
  selected={true},
  title={Learning Gradient Fields for Scalable and Generalizable Irregular Packing},
  author={Xue*, Tianyang and Wu*, Mingdong and Lu, Lin and Wang, Haoxuan and Dong, Hao and Chen, Baoquan},
  journal={SIGGRAPH Asia},
  year={2023}
}


@article{cheng2023score,
  code={https://github.com/J-F-Cheng/Score-PA_Score-based-3D-Part-Assembly},
  preview={score_pa_v2.gif},
  pdf={https://arxiv.org/pdf/2309.04220v1.pdf},
  oral="Oral",
  abbr={BMVC 2023},
  bibtex_show={true},
  selected={true},
  title={Score-PA: Score-based 3D Part Assembly},
  author={Cheng, Junfeng and Wu, Mingdong and Zhang, Ruiyuan and Zhan, Guanqi and Wu, Chao and Dong, Hao},
  journal={British Machine Vision Conference},
  year={2023}
}


@article{wang2023learning,
  website={https://sites.google.com/view/sasavan/},
  code={https://github.com/wwwwwyyyyyxxxxx/SA2GVAN},
  preview={2023RAL-Visual-Audio-Nav-min.png},
  pdf={https://arxiv.org/pdf/2304.10773.pdf},
  abbr={RAL 2023},
  bibtex_show={true},
  selected={false},
  title={Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation},
  author={Wang, Hongcheng and Wang, Yuxuan and Zhong, Fangwei and Wu, Mingdong and Zhang, Jianwei and Wang, Yizhou and Dong, Hao},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}


@inproceedings{ci2023gfpose,
  sota_link={https://paperswithcode.com/sota/multi-hypotheses-3d-human-pose-estimation-on?p=gfpose-learning-3d-human-pose-prior-with},
  sota_badge={https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/gfpose-learning-3d-human-pose-prior-with/multi-hypotheses-3d-human-pose-estimation-on},
  website={https://sites.google.com/view/gfpose/home},
  code={https://github.com/Embracing/GFPose},
  star={https://img.shields.io/github/stars/Embracing/GFPose?style=social&amp;label=Code+Stars},
  preview={gfpose_v2.gif},
  pdf={https://arxiv.org/abs/2212.08641},
  abbr={CVPR 2023},
  bibtex_show={true},
  selected={true},
  title={GFPose: Learning 3d human pose prior with gradient fields},
  author={Ci, Hai and Wu, Mingdong and Zhu, Wentao and Ma, Xiaoxuan and Dong, Hao and Zhong, Fangwei and Wang, Yizhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4800--4810},
  year={2023},
  abstract={
    GFPose is a unified 3D human pose prior model that can be easily used for various applications, e.g., 3D human pose estimation, pose denoising and generation. 
    Our key idea is to estimate the gradient field (a.k.a, score) of the perturbed human pose. 
    We can leverage the gradient to adjust poses to be more plausible and feasible to a task specification. 
  }
}


@inproceedings{wu2022targf,
  website={https://sites.google.com/view/targf},
  code={https://github.com/AaronAnima/TarGF},
  preview={targf_update.gif},
  pdf={https://arxiv.org/abs/2209.00853},
  abbr={NeurIPS 2022},
  bibtex_show={true},
  selected={true},
  title={Tar{GF}: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification},
  author={Wu*, Mingdong and Zhong*, Fangwei and Xia, Yulong and Dong, Hao},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=Euv1nXN98P3},
  abstract={
    We study object rearrangement without explicit goal specification.
    The agent is given examples from a target distribution and aims at rearranging objects to increase the likelihood of the distribution.
    Our key idea is to learn a target gradient field that indicates the fastest direction to increase the likelihood from examples via score-matching.
  }
}



